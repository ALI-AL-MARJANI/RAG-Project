{
  "id": "2511.17467",
  "content": "PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for\nPersonalized LLM\n\nSiqi Liang1*\u2020, Yudi Zhang2*, Yue Guo3\n1Purdue University\n2Iowa State University\n3Columbia University\n\n5\n2\n0\n2\n\nv\no\nN\n1\n2\n\n]\n\nG\nL\n.\ns\nc\n[\n\n1\nv\n7\n6\n4\n7\n1\n.\n1\n1\n5\n2\n:\nv\ni\nX\nr\na\n\nAbstract\n\nWe propose a novel framework for persona-based language\nmodel system, motivated by the need for personalized AI\nto individual user preferences. In our\nagents that adapt\napproach,\nthe agent embodies the user\u2019s \u201cpersona\u201d (e.g.\nuser profile or taste) and is powered by a large language\nmodel (LLM). To enable the agent to leverage rich contex-\ntual information, we introduce a Knowledge-Graph-enhanced\nRetrieval-Augmented Generation (Graph RAG) mechanism\nthat constructs an LLM-derived graph index of relevant doc-\numents and summarizes communities of related information.\nOur framework generates personalized prompts by combin-\ning: (1) a summary of the user\u2019s historical behaviors and\npreferences extracted from the knowledge graph, and (2) rel-\nevant global interaction patterns identified through graph-\nbased community detection. This dynamic prompt engineer-\ning approach allows the agent to maintain consistent persona-\naligned behaviors while benefiting from collective knowl-\nedge. On the LaMP benchmark, our method improves news\ncategorization F1 by 11.1%, movie tagging F1 by 56.1%, and\nreduces product rating MAE by 10.4% over prior methods.\nOur code is available at https://anonymous.4open.science/r/\nPersonaAgentwGraphRAG-DE6F\n\nIntroduction\nLarge Language Models (LLMs) have shown strong perfor-\nmance across applications, from recommendation tasks (Xu\nand Zhang 2025; Liang, Zhang, and Wang 2025; Yu et al.\n2025; Said 2025; Lin and et al. 2023) to agent-based sys-\ntems capable of reasoning, dialogue, and tool use (Ruan and\net al. 2023). While earlier work applied LLMs to isolated\ncomponents of recommender systems, recent agent-based\napproaches address more ambitious challenges such as\nlong-horizon decision-making, collaboration, and domain-\nspecific reasoning (Wang et al. 2024), often enhanced with\nmemory, planning, retrieval, and inter-agent communica-\ntion for tasks like tutoring, simulation, and assistant work-\nflows (Zou et al. 2025).\n\n*These authors contributed equally.\n\u2020Equal\n\ncontribution (alphabetical order). Corresponding\nauthors: Siqi Liang (lsq950917@gmail.com), Yudi Zhang\n(yudiz@iastate.edu)\nCopyright \u00a9 2026, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n\nWithin this paradigm, persona-driven agents are increas-\ningly important for personalization: in recommender sys-\ntems, an agent may reflect a user\u2019s taste profile; in decision-\nsupport, it may simulate an expert\u2019s reasoning style. By en-\ncoding preferences and behaviors into a natural language\npersona, LLMs can adapt outputs to individual users, achiev-\ning personalized behavior across dialogue, reasoning, and\nrecommendation (Kenan Jiang 2024; Samuel, Zou, and et al.\n2024). However, most prior work relies on static personas or\ntemplates, without dynamically incorporating evolving be-\nhaviors or community knowledge. In domains like movie\nrecommendation or e-commerce, agents must produce de-\ncisions aligned with changing preferences, motivating our\nframework for persona-based LLM agents that ground out-\nputs in both individual and collective knowledge.\n\nOur system integrates three components: (1) a per-\nsona prompt encoding user preferences; (2) a knowledge\ngraph capturing personal interactions and community pat-\nterns (Chen and et al. 2024; Xu and et al. 2024); and (3)\na GraphRAG mechanism that retrieves and synthesizes rel-\nevant context. Given a query, dense search identifies can-\ndidate nodes, graph traversal collects related user and item\nsignals, and the resulting subgraph is linearized and com-\nbined with the persona prompt for generation. This enables\ngrounding in both user history and community wisdom, sup-\nporting accurate and explainable personalization (Mansour\nand et al. 2024; Zerhoudi and Granitzer 2024).\n\nTo our knowledge, this is the first system to combine\ngraph-based retrieval with dynamic persona prompting de-\nrived from both individual and community patterns. The re-\nsult is a knowledge-aware, preference-aligned agent that im-\nproves personalization in tasks such as movie tagging and\nproduct rating.\n\nRelated Work\n\nPersona-Based LLM Agents\nRecent work has begun to endow LLM agents with ex-\nplicit personas to achieve personalized behavior. Persona\nagents have demonstrated improved contextual and person-\nalized responses across applications such as tutoring, cus-\ntomer support, and gaming (Zhang and et al. 2024). Per-\nsonaGym (Samuel, Zou, and et al. 2024) measures whether\nagents take optimal actions aligned with their personas,\n\n \n \n \n \n \n \n\fFigure 1: Overview of the PersonaAgent with GraphRAG framework.\n\nit assesses adherence to persona-specific communication\nstyles, consistency in persona attributes, and avoidance of\nharmful outputs. HARBOR (Kenan Jiang 2024) explores\nhow an agent\u2019s assigned persona affects its bidding behav-\nior, whether agents can accurately profile competitors\u2019 per-\nsonas during auctions. Other studies have shown that per-\nsona prompts allow agents to extrapolate consistent prefer-\nences (e.g., adjusting answers about a tractor differently for\na farmer vs. an urban planner persona). However, most prior\nwork focuses on static personas or template-based personal-\nization, rather than dynamically incorporating user behavior\npatterns and community knowledge.\n\nMemory and Knowledge Integration in LLM\nSystems\nMemory and knowledge integration are critical for maintain-\ning consistent and informed agent behavior. LLM-memory\nsystems typically combine short-term context windows with\nlong-term external memories (Xu and et al. 2024; Chen and\net al. 2024). For example, Xu et al (Xu and et al. 2024)\nproposes a sophisticated memory architecture with multi-\nple specialized memory types (episodic, semantic, procedu-\nral, etc) to support complex reasoning tasks. More generally,\nsurveys have drawn analogies between human memory sys-\ntems and AI memory modules (Chen and et al. 2024). These\ninsights inform our approach to maintaining user preference\nhistories and behavioral patterns.\n\nRetrieval-Augmented Generation and Knowledge\nGraphs\nRetrieval-Augmented Generation (RAG) techniques use ex-\nternal knowledge to improve LLM outputs. Classical RAG\napproaches select relevant text passages via sparse term-\nmatching or dense embedding search (Lewis and et al. 2023;\nMansour and et al. 2024). Recent work has extended this\nto graph-based knowledge structures. Graph-based RAG\n(GraphRAG) enriches retrieval with structured knowledge\n\ngraphs: after an initial search for relevant entities, the system\ntraverses graph links to gather related information (Man-\nsour and et al. 2024; Zerhoudi and Granitzer 2024). This ap-\nproach grounds LLMs in relational data, improving factual\naccuracy and explainability. Our framework builds on these\nideas by encoding both domain knowledge and user behav-\nior patterns in a knowledge graph, using a combination of\nvector retrieval and graph expansion to construct personal-\nized contexts for the LLM.\n\nMethodology\nOur PersonaAgent system leverages Knowledge Graph-\nbased GraphRAG to enable personalized content genera-\ntion. The system combines individual user preferences with\nbroader community insights through a structured knowledge\ngraph and personalized prompt generation (see Fig 1).\n\nKnowledge Graph Construction\nOur system maintains a heterogeneous knowledge graph\nG = (V, E) where nodes V represent:\n\n1. Interaction nodes: Represent user interactions and con-\ntain metadata such as title, text, category, and timestamp.\n2. Concept nodes: Represent extracted named entities and\ndomain-relevant keywords from interaction text. These\nnodes generalize across users and support semantic rea-\nsoning.\n\n3. Category nodes: Represent high-level content domains,\nlinking interactions with broader thematic structures.\n\nEdges E in the graph capture semantic relationships be-\n\ntween nodes:\n\n\u2022 Interaction \u2194 Category: Connects interactions to their\n\ncategorical domain.\n\n\u2022 Interaction \u2194 Concept: Links an interaction to its ex-\n\ntracted concepts or entities.\n\n\f\u2022 Concept \u2194 Concept: Can be inferred via co-occurrence\nacross interactions or shared categories to enable graph-\nbased community detection.\n\nFor each new interaction, the system 1) Creates an interac-\ntion node with unique identifier; 2) Extracts relevant con-\ncepts using pattern-based and domain-specific methods; 3)\nEstablishes connections to existing nodes based on semantic\nrelationships.\n\nGraphRAG Retrieval Mechanism\nThe system employs a dual-source retrieval approach that\ncombines personal and community-based insights:\n\nUser-Specific Retrieval For a given user u and query q,\n\nwe retrieve relevant interactions from their history:\n\nIuser(u, q) = TopK(sim(q, i) : i \u2208 Hu)\n\nwhere Hu represents user u\u2019s interaction history and sim\nrefers to the Cosine similarity measured by TF-IDF.\n\nGlobal Retrieval We augment personal context with rel-\n\nevant community interactions:\n\nIglobal(u, q) = TopK(sim(q, i) : i \u2208 Hall \\ Hu)\n\nThe combined semantic context C(u, q) includes:\n\nC(u, q) = {Iuser(u, q), Iglobal(u, q),\nPcat(u), Econcepts(u, q)}\n\n(1)\n(2)\n\nwhere Pcat(u) represents user category preferences and\nEconcepts(u, q) contains relevant concepts.\n\nPersonalized Prompt Generation\nThe system generates context-rich prompts by combining:\n1) Task-specific instructions and available categories; 2) Re-\ntrieved personal interactions with relevance scores; 3) Re-\nlated global community interactions and patterns; 4) User\npreference distributions; 5) Relevant concept clusters.\n\nThe prompt construction process follows:\n\nAlgorithm 1: Personalized Prompt Generation\n\nRequire: User ID u, Query q, Categories C\nEnsure: Personalized prompt P\n1: context \u2190 GetSemanticContext(u, q)\n2: content \u2190 ExtractTaskContent(q)\n3: P \u2190 InitializeBasePrompt(content, C)\n4: P \u2190 P + FormatUserIntereaction\n5: P \u2190 P + FormatCommunityIntereaction\n6: P \u2190 P + FormatPreferencesAndConcepts(context)\n7: return P\n\nResults\n\nData Description\nWe evaluate our\nframework using the LaMP bench-\nmark (Salemi et al. 2023), focusing on three decision-\nmaking tasks: news categorization, movie tagging, and prod-\nuct rating. These tasks enable us to assess the effectiveness\n\nof personalized agents across diverse personalization do-\nmains. Following the data processing procedure described\nin (Zhang and et al. 2024), we construct test sets by selecting\nthe 100 users with the most extensive activity histories from\nthe time-ordered version of the LaMP dataset. In the train-\ning sets which are used to construct the knowledge graph,\nthe news data includes 274 users, the movie data includes\n829 users, and product rating includes 1000 users.\n\nMetircs Comparison\nTable 1 presents results on three personalized tasks:\nnews categorization (LaMP-2N), movie tagging (LaMP-\n2M), and product rating (LaMP-3). PersonaAgent with\nGraphRAG consistently outperforms all baselines includ-\ning non-personalized LLMs (Liu et al. 2021), retrieval-\naugmented prompting (ReAct) (Yao et al. 2023), memory-\nbased models (MemBank) (Zhong et al. 2023), and the prior\nstate-of-the-art PersonaAgent (Zhang and et al. 2024). On\nLaMP-2N, it achieves 0.804 accuracy and 0.591 F1, improv-\ning over PersonaAgent by 1.0% and 11.1%, respectively.\nOn LaMP-2M, the gains are larger, with accuracy increasing\nfrom 0.513 to 0.653 (+27.3%) and F1 from 0.424 to 0.662\n(+56.1%), demonstrating stronger personalization for sub-\njective behaviors. For LaMP-3, GraphRAG reduces MAE\nfrom 0.241 to 0.216 (\u201310.4%) and RMSE from 0.509 to\n0.484 (\u20134.9%), indicating more precise rating prediction. We\nalso noticed that with our method, small models, such as\nLLaMA3 can perform better than competing methods, for\nexample, on the movie data, accuracy can be improved by\n13.6%. These results highlight the value of integrating struc-\ntured user memory with graph-based retrieval.\n\nFigure 2: LLMs Comparison on LaMP-2N\n\nFigure 2 compares five language models\u2014Mistral\nSmall (Jiang and et al. 2023), LLaMA2-7B (Touvron and\net al. 2023), LLaMA3-8B (AI 2024), Claude 3.5 Sonnet,\nand Claude 4 (Anthropic 2024)\u2014on the LaMP-2N per-\nsonalized news categorization task. Mistral Small performs\nworst across all metrics, reflecting its limited capacity for\npersonalization. LLaMA2-7B shows strong results, rivaling\nLLaMA3-8B in Accuracy and Recall despite its smaller size,\nwhile LLaMA3-8B offers more balanced improvements in\nF1 and Recall. Among Claude models, Claude 3.5 Sonnet\nachieves the best overall performance, with the highest F1\n\n\fMetrics Non-Personalized ReAct MemBank PersonaAgent\n\nLaMP-2N: Personalized\nNews Categorization\nLaMP-2M: Personalized\nMovie Tagging\nLaMP-3: Personalized\nProduct Rating\n\nAcc\nF1\nAcc\nF1\nMAE\nRMSE\n\n0.660\n0.386\n0.387\n0.302\n0.295\n0.590\n\n0.639\n0.381\n0.450\n0.378\n0.313\n0.590\n\n0.741\n0.456\n0.470\n0.391\n0.321\n0.582\n\n0.796*\n0.532*\n0.513*\n0.424\n0.241*\n0.509*\n\nTable 1: Performance comparison across different tasks and models\n\nPersonaAgent\nwith GraphRAG\n0.804\n0.591\n0.653\n0.662\n0.216\n0.484\n\nFigure 3: Case study of PersonaAgent with GraphRAG for personalized classification\n\nand Recall, highlighting its superior alignment with user-\nspecific content. By contrast, Claude 4 underperforms across\nall metrics, often overcomplicating the task and failing to\nprovide correct answers.\n\nCase Study\n\nThe example in Fig 3 demonstrates that incorporating glob-\nally similar interactions from other users into the person-\nalization prompt substantially improves classification ac-\ncuracy by providing a broader contextual grounding be-\nyond a single user\u2019s history. In our example, the LLaMA3-\n8B model misclassified an article about a Parkland shoot-\ning survivor\u2019s essay for Teen Vogue as belonging to the\n\u201cwomen\u201d category when only the user\u2019s personal interaction\nhistory was considered. This error is likely due to the user\u2019s\nstrong historical preference for women-focused protest arti-\ncles, which skewed the model\u2019s prediction. However, when\nwe enriched the prompt with globally similar articles\u2014such\nas those involving youth activism and gun law reform (e.g.,\n\u201cTeen Survivors Of Florida Shooting To March On Wash-\nington\u201d)\u2014the model correctly classified the article as \u201cpol-\nitics\u201d. These globally similar interactions helped steer the\nmodel toward the correct thematic alignment by introducing\nrelevant but more nuanced examples, thus balancing person-\nalization with generalizability. This demonstrates that com-\nmunity context acts as a corrective signal, especially when\na user\u2019s preferences are strongly skewed or lack diversity\nacross topics.\n\nConclusion\n\nWe introduced PersonaAgent with GraphRAG, a frame-\nwork that integrates persona-driven prompting with graph-\nenhanced retrieval to provide accurate, explainable, and con-\nsistent personalization. By leveraging both user-specific his-\ntories and global community patterns, the system balances\nindividual preferences with collective knowledge, yielding\nimprovements in news categorization, movie tagging, and\nproduct rating.\n\nLooking forward, two promising directions emerge. First,\nmulti-agent collaboration, where persona agents interact, ne-\ngotiate, and share knowledge, could enhance robustness and\nenable collective intelligence for recommendation, classifi-\ncation, and decision-support. Second, incorporating inverse\nreinforcement learning (IRL) (Beliaev and Sadigh 2024; Ke\net al. 2025; Jeon et al. 2020) would allow agents to infer\nlatent preference signals from behavior, aligning with both\nexplicit histories and implicit reward structures. This could\nproduce agents that better adapt to evolving goals while re-\nmaining consistent with user values.\n\nReferences\n\nAI, M. 2024. LLaMA 3 8B.\n\nAnthropic. 2024. Claude 3.5 Sonnet.\n\nInverse Reinforcement\nBeliaev, M.; and Sadigh, D. 2024.\nLearning by Estimating Expertise of Demonstrators. arXiv\npreprint. Extended version of AAAI publication.\n\n\fZerhoudi, S.; and Granitzer, M. 2024.\nPersonaRAG:\nEnhancing Retrieval-Augmented Generation Systems with\nUser-Centric Agents. arXiv preprint arXiv:2407.09394.\nZhang, W.; and et al. 2024. PersonaAgent: When Large\nLanguage Model Agents Meet Personalization at Test Time.\narXiv preprint arXiv:2506.06254.\nZhong, W.; Guo, L.; Gao, Q.; and et al. 2023. MemoryBank:\nEnhancing Large Language Models with Long-Term Mem-\nory. arXiv:2305.10250.\nZou, H. P.; Huang, W.-C.; Wu, Y.; ; and et al. 2025. LLM-\nBased Human-Agent Collaboration and Interaction Sys-\ntems: A Survey. arXiv:2505.00753.\n\nChen, J.; and et al. 2024. From Persona to Personalization:\nA Survey on Role-Playing Language Agents. arXiv preprint\narXiv:2404.18231.\nJeon, W.; Su, C.-Y.; Barde, P.; and et al. 2020. Regularized\nInverse Reinforcement Learning. arXiv:2010.03691.\nJiang, A. Q.; and et al. 2023. Mistral 7B. arXiv:2310.06825.\nKe, J.; Wu, F.; Wang, J.; and et al. 2025. Inverse Reinforce-\nment Learning with Switching Rewards and History Depen-\ndency. In ICLR. Submission 10850.\nKenan Jiang, F. L., Li Xiong. 2024. HARBOR: Explor-\ning Persona Dynamics in Multi-Agent Competition. arXiv\npreprint arXiv:2502.12149.\nLewis, P.; and et al. 2023. Retrieval-Augmented Genera-\ntion for Knowledge-Intensive NLP Tasks: A Survey. arXiv\npreprint arXiv:2303.06519.\nLiang, S.; Zhang, Y.; and Wang, Y. 2025. C-TLSAN:\nContent-Enhanced Time-Aware Long-and Short-Term At-\ntention Network for Personalized Recommendation. arXiv\npreprint arXiv:2506.13021.\nLin, J.; and et al. 2023. How Can Recommender Systems\nBenefit from Large Language Models: A Survey. arXiv\npreprint arXiv:2306.05817.\nLiu, J.; Shen, D.; Zhang, Y.; and et al. 2021. What Makes\nGood In-Context Examples for GPT-3? arXiv:2101.06804.\nMansour, S.; and et al. 2024. PAARS: Persona Aligned\nAgentic Retail Shoppers. arXiv preprint arXiv:2506.13021.\nRuan, J.; and et al. 2023. TPTU: Large Language Model-\nbased AI Agents for Task Planning and Tool Usage. arXiv\npreprint arXiv:2308.03427.\nSaid, A. 2025. On explaining recommendations with Large\nLanguage Models: a review. Frontiers in Big Data, 7:\n1505284.\nSalemi, A.; Mysore, S.; Bendersky, M.; and et al. 2023.\nLaMP: When Large Language Models Meet Personaliza-\ntion. arXiv:2304.11406.\nSamuel, V.; Zou, H. P.; and et al., Y. Z. 2024. PersonaGym:\narXiv preprint\nEvaluating Persona Agents and LLMs.\narXiv:2407.18416.\nTouvron, H.; and et al. 2023. Llama 2: Open Foundation and\nFine-Tuned Chat Models. arXiv:2307.09288.\nWang, L.; Ma, C.; Feng, X.; and et al. 2024. A survey on\nlarge language model based autonomous agents. Frontiers\nof Computer Science, 18(6).\nXu, R.; and et al. 2024. Character is Destiny: Can Role-\nPlaying Language Agents Make Persona-Driven Decisions?\narXiv preprint arXiv:2404.12138.\nXu, Z.; and Zhang, Y. 2025.\ning\narXiv:2507.16237.\nYao, S.; Zhao, J.; Yu, D.; and et al. 2023.\nReAct:\nSynergizing Reasoning and Acting in Language Models.\narXiv:2210.03629.\nYu, P.; Xu, Z.; Wang, J.; and et al. 2025. The Application\nof Large Language Models in Recommendation Systems.\narXiv preprint arXiv:2501.02178. ArXiv:2501.02178v2.\n\nLLM-Enhanced Rerank-\nProduct Recommendation.\n\nfor Complementary\n\n\f"
}