{
  "id": "2511.17467",
  "chunks": [
    "PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM Siqi Liang1*\u2020, Yudi Zhang2*, Yue Guo3 1Purdue University 2Iowa State University 3Columbia University 5 2 0 2 v o N 1 2 ] G L . s c [ 1 v 7 6 4 7 1 . 1 1 5 2 : v i X r a Abstract We propose a novel framework for persona-based language model system, motivated by the need for personalized AI to individual user preferences. In our agents that adapt approach, the agent embodies the user\u2019s \u201cpersona\u201d (e.g. user profile or taste) and is powered by a large language model (LLM). To enable the agent to leverage rich contex- tual information, we introduce a Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism that constructs an LLM-derived graph index of relevant doc- uments and summarizes communities of related information. Our framework generates personalized prompts by combin- ing: (1) a summary of the user\u2019s historical behaviors and preferences extracted from the knowledge graph, and (2) rel- evant global interaction patterns identified through graph- based community detection. This dynamic prompt engineer- ing approach allows the agent to maintain consistent persona- aligned behaviors while benefiting from collective knowl- edge. On the LaMP benchmark, our method improves news categorization F1 by 11.1%, movie tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior methods. Our code is available at https://anonymous.4open.science/r/ PersonaAgentwGraphRAG-DE6F Introduction Large Language Models (LLMs) have shown strong perfor- mance across applications, from recommendation tasks (Xu and Zhang 2025; Liang, Zhang, and Wang 2025; Yu et al. 2025; Said 2025; Lin and et al. 2023) to agent-based sys- tems capable of reasoning, dialogue, and tool use (Ruan and et al. 2023). While earlier work applied LLMs to isolated components of recommender systems, recent agent-based approaches address more ambitious challenges such as long-horizon decision-making, collaboration, and domain- specific reasoning (Wang et al. 2024), often enhanced with memory, planning, retrieval, and inter-agent communica- tion for tasks like tutoring, simulation, and assistant work- flows (Zou et al. 2025). *These authors contributed equally. \u2020Equal contribution (alphabetical order). Corresponding authors: Siqi Liang (lsq950917@gmail.com), Yudi Zhang (yudiz@iastate.edu) Copyright \u00a9 2026, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Within this paradigm, persona-driven agents are increas- ingly important for personalization: in recommender sys- tems, an agent may reflect a user\u2019s taste profile; in decision- support, it may simulate an expert\u2019s reasoning style. By en- coding preferences and behaviors into a natural language persona, LLMs can adapt outputs to individual users, achiev- ing personalized behavior across dialogue, reasoning, and recommendation (Kenan Jiang 2024; Samuel, Zou, and et al. 2024). However, most prior work relies on static personas or templates, without dynamically incorporating evolving be- haviors or community knowledge. In domains like movie recommendation or e-commerce, agents must produce de- cisions aligned with changing preferences, motivating our framework for persona-based LLM agents that ground out- puts in both individual and collective knowledge. Our system integrates three components: (1) a per- sona prompt encoding user preferences; (2)",
    "across dialogue, reasoning, and recommendation (Kenan Jiang 2024; Samuel, Zou, and et al. 2024). However, most prior work relies on static personas or templates, without dynamically incorporating evolving be- haviors or community knowledge. In domains like movie recommendation or e-commerce, agents must produce de- cisions aligned with changing preferences, motivating our framework for persona-based LLM agents that ground out- puts in both individual and collective knowledge. Our system integrates three components: (1) a per- sona prompt encoding user preferences; (2) a knowledge graph capturing personal interactions and community pat- terns (Chen and et al. 2024; Xu and et al. 2024); and (3) a GraphRAG mechanism that retrieves and synthesizes rel- evant context. Given a query, dense search identifies can- didate nodes, graph traversal collects related user and item signals, and the resulting subgraph is linearized and com- bined with the persona prompt for generation. This enables grounding in both user history and community wisdom, sup- porting accurate and explainable personalization (Mansour and et al. 2024; Zerhoudi and Granitzer 2024). To our knowledge, this is the first system to combine graph-based retrieval with dynamic persona prompting de- rived from both individual and community patterns. The re- sult is a knowledge-aware, preference-aligned agent that im- proves personalization in tasks such as movie tagging and product rating. Related Work Persona-Based LLM Agents Recent work has begun to endow LLM agents with ex- plicit personas to achieve personalized behavior. Persona agents have demonstrated improved contextual and person- alized responses across applications such as tutoring, cus- tomer support, and gaming (Zhang and et al. 2024). Per- sonaGym (Samuel, Zou, and et al. 2024) measures whether agents take optimal actions aligned with their personas, Figure 1: Overview of the PersonaAgent with GraphRAG framework. it assesses adherence to persona-specific communication styles, consistency in persona attributes, and avoidance of harmful outputs. HARBOR (Kenan Jiang 2024) explores how an agent\u2019s assigned persona affects its bidding behav- ior, whether agents can accurately profile competitors\u2019 per- sonas during auctions. Other studies have shown that per- sona prompts allow agents to extrapolate consistent prefer- ences (e.g., adjusting answers about a tractor differently for a farmer vs. an urban planner persona). However, most prior work focuses on static personas or template-based personal- ization, rather than dynamically incorporating user behavior patterns and community knowledge. Memory and Knowledge Integration in LLM Systems Memory and knowledge integration are critical for maintain- ing consistent and informed agent behavior. LLM-memory systems typically combine short-term context windows with long-term external memories (Xu and et al. 2024; Chen and et al. 2024). For example, Xu et al (Xu and et al. 2024) proposes a sophisticated memory architecture with multi- ple specialized memory types (episodic, semantic, procedu- ral, etc) to support complex reasoning tasks. More generally, surveys have drawn analogies between human memory sys- tems and AI memory modules (Chen and et al. 2024). These insights inform our approach to maintaining user preference histories and behavioral patterns. Retrieval-Augmented Generation and Knowledge Graphs Retrieval-Augmented Generation (RAG) techniques use ex- ternal knowledge to",
    "al. 2024). For example, Xu et al (Xu and et al. 2024) proposes a sophisticated memory architecture with multi- ple specialized memory types (episodic, semantic, procedu- ral, etc) to support complex reasoning tasks. More generally, surveys have drawn analogies between human memory sys- tems and AI memory modules (Chen and et al. 2024). These insights inform our approach to maintaining user preference histories and behavioral patterns. Retrieval-Augmented Generation and Knowledge Graphs Retrieval-Augmented Generation (RAG) techniques use ex- ternal knowledge to improve LLM outputs. Classical RAG approaches select relevant text passages via sparse term- matching or dense embedding search (Lewis and et al. 2023; Mansour and et al. 2024). Recent work has extended this to graph-based knowledge structures. Graph-based RAG (GraphRAG) enriches retrieval with structured knowledge graphs: after an initial search for relevant entities, the system traverses graph links to gather related information (Man- sour and et al. 2024; Zerhoudi and Granitzer 2024). This ap- proach grounds LLMs in relational data, improving factual accuracy and explainability. Our framework builds on these ideas by encoding both domain knowledge and user behav- ior patterns in a knowledge graph, using a combination of vector retrieval and graph expansion to construct personal- ized contexts for the LLM. Methodology Our PersonaAgent system leverages Knowledge Graph- based GraphRAG to enable personalized content genera- tion. The system combines individual user preferences with broader community insights through a structured knowledge graph and personalized prompt generation (see Fig 1). Knowledge Graph Construction Our system maintains a heterogeneous knowledge graph G = (V, E) where nodes V represent: 1. Interaction nodes: Represent user interactions and con- tain metadata such as title, text, category, and timestamp. 2. Concept nodes: Represent extracted named entities and domain-relevant keywords from interaction text. These nodes generalize across users and support semantic rea- soning. 3. Category nodes: Represent high-level content domains, linking interactions with broader thematic structures. Edges E in the graph capture semantic relationships be- tween nodes: \u2022 Interaction \u2194 Category: Connects interactions to their categorical domain. \u2022 Interaction \u2194 Concept: Links an interaction to its ex- tracted concepts or entities. \u2022 Concept \u2194 Concept: Can be inferred via co-occurrence across interactions or shared categories to enable graph- based community detection. For each new interaction, the system 1) Creates an interac- tion node with unique identifier; 2) Extracts relevant con- cepts using pattern-based and domain-specific methods; 3) Establishes connections to existing nodes based on semantic relationships. GraphRAG Retrieval Mechanism The system employs a dual-source retrieval approach that combines personal and community-based insights: User-Specific Retrieval For a given user u and query q, we retrieve relevant interactions from their history: Iuser(u, q) = TopK(sim(q, i) : i \u2208 Hu) where Hu represents user u\u2019s interaction history and sim refers to the Cosine similarity measured by TF-IDF. Global Retrieval We augment personal context with rel- evant community interactions: Iglobal(u, q) = TopK(sim(q, i) : i \u2208 Hall \\ Hu) The combined semantic context C(u, q) includes: C(u, q) = {Iuser(u, q), Iglobal(u, q), Pcat(u), Econcepts(u, q)} (1) (2)",
    "given user u and query q, we retrieve relevant interactions from their history: Iuser(u, q) = TopK(sim(q, i) : i \u2208 Hu) where Hu represents user u\u2019s interaction history and sim refers to the Cosine similarity measured by TF-IDF. Global Retrieval We augment personal context with rel- evant community interactions: Iglobal(u, q) = TopK(sim(q, i) : i \u2208 Hall \\ Hu) The combined semantic context C(u, q) includes: C(u, q) = {Iuser(u, q), Iglobal(u, q), Pcat(u), Econcepts(u, q)} (1) (2) where Pcat(u) represents user category preferences and Econcepts(u, q) contains relevant concepts. Personalized Prompt Generation The system generates context-rich prompts by combining: 1) Task-specific instructions and available categories; 2) Re- trieved personal interactions with relevance scores; 3) Re- lated global community interactions and patterns; 4) User preference distributions; 5) Relevant concept clusters. The prompt construction process follows: Algorithm 1: Personalized Prompt Generation Require: User ID u, Query q, Categories C Ensure: Personalized prompt P 1: context \u2190 GetSemanticContext(u, q) 2: content \u2190 ExtractTaskContent(q) 3: P \u2190 InitializeBasePrompt(content, C) 4: P \u2190 P + FormatUserIntereaction 5: P \u2190 P + FormatCommunityIntereaction 6: P \u2190 P + FormatPreferencesAndConcepts(context) 7: return P Results Data Description We evaluate our framework using the LaMP bench- mark (Salemi et al. 2023), focusing on three decision- making tasks: news categorization, movie tagging, and prod- uct rating. These tasks enable us to assess the effectiveness of personalized agents across diverse personalization do- mains. Following the data processing procedure described in (Zhang and et al. 2024), we construct test sets by selecting the 100 users with the most extensive activity histories from the time-ordered version of the LaMP dataset. In the train- ing sets which are used to construct the knowledge graph, the news data includes 274 users, the movie data includes 829 users, and product rating includes 1000 users. Metircs Comparison Table 1 presents results on three personalized tasks: news categorization (LaMP-2N), movie tagging (LaMP- 2M), and product rating (LaMP-3). PersonaAgent with GraphRAG consistently outperforms all baselines includ- ing non-personalized LLMs (Liu et al. 2021), retrieval- augmented prompting (ReAct) (Yao et al. 2023), memory- based models (MemBank) (Zhong et al. 2023), and the prior state-of-the-art PersonaAgent (Zhang and et al. 2024). On LaMP-2N, it achieves 0.804 accuracy and 0.591 F1, improv- ing over PersonaAgent by 1.0% and 11.1%, respectively. On LaMP-2M, the gains are larger, with accuracy increasing from 0.513 to 0.653 (+27.3%) and F1 from 0.424 to 0.662 (+56.1%), demonstrating stronger personalization for sub- jective behaviors. For LaMP-3, GraphRAG reduces MAE from 0.241 to 0.216 (\u201310.4%) and RMSE from 0.509 to 0.484 (\u20134.9%), indicating more precise rating prediction. We also noticed that with our method, small models, such as LLaMA3 can perform better than competing methods, for example, on the movie data, accuracy can be improved by 13.6%. These results highlight the value of integrating struc- tured user memory with graph-based retrieval. Figure 2: LLMs Comparison on LaMP-2N Figure 2 compares five language models\u2014Mistral Small (Jiang and et al. 2023), LLaMA2-7B (Touvron and et al. 2023), LLaMA3-8B",
    "RMSE from 0.509 to 0.484 (\u20134.9%), indicating more precise rating prediction. We also noticed that with our method, small models, such as LLaMA3 can perform better than competing methods, for example, on the movie data, accuracy can be improved by 13.6%. These results highlight the value of integrating struc- tured user memory with graph-based retrieval. Figure 2: LLMs Comparison on LaMP-2N Figure 2 compares five language models\u2014Mistral Small (Jiang and et al. 2023), LLaMA2-7B (Touvron and et al. 2023), LLaMA3-8B (AI 2024), Claude 3.5 Sonnet, and Claude 4 (Anthropic 2024)\u2014on the LaMP-2N per- sonalized news categorization task. Mistral Small performs worst across all metrics, reflecting its limited capacity for personalization. LLaMA2-7B shows strong results, rivaling LLaMA3-8B in Accuracy and Recall despite its smaller size, while LLaMA3-8B offers more balanced improvements in F1 and Recall. Among Claude models, Claude 3.5 Sonnet achieves the best overall performance, with the highest F1 Metrics Non-Personalized ReAct MemBank PersonaAgent LaMP-2N: Personalized News Categorization LaMP-2M: Personalized Movie Tagging LaMP-3: Personalized Product Rating Acc F1 Acc F1 MAE RMSE 0.660 0.386 0.387 0.302 0.295 0.590 0.639 0.381 0.450 0.378 0.313 0.590 0.741 0.456 0.470 0.391 0.321 0.582 0.796* 0.532* 0.513* 0.424 0.241* 0.509* Table 1: Performance comparison across different tasks and models PersonaAgent with GraphRAG 0.804 0.591 0.653 0.662 0.216 0.484 Figure 3: Case study of PersonaAgent with GraphRAG for personalized classification and Recall, highlighting its superior alignment with user- specific content. By contrast, Claude 4 underperforms across all metrics, often overcomplicating the task and failing to provide correct answers. Case Study The example in Fig 3 demonstrates that incorporating glob- ally similar interactions from other users into the person- alization prompt substantially improves classification ac- curacy by providing a broader contextual grounding be- yond a single user\u2019s history. In our example, the LLaMA3- 8B model misclassified an article about a Parkland shoot- ing survivor\u2019s essay for Teen Vogue as belonging to the \u201cwomen\u201d category when only the user\u2019s personal interaction history was considered. This error is likely due to the user\u2019s strong historical preference for women-focused protest arti- cles, which skewed the model\u2019s prediction. However, when we enriched the prompt with globally similar articles\u2014such as those involving youth activism and gun law reform (e.g., \u201cTeen Survivors Of Florida Shooting To March On Wash- ington\u201d)\u2014the model correctly classified the article as \u201cpol- itics\u201d. These globally similar interactions helped steer the model toward the correct thematic alignment by introducing relevant but more nuanced examples, thus balancing person- alization with generalizability. This demonstrates that com- munity context acts as a corrective signal, especially when a user\u2019s preferences are strongly skewed or lack diversity across topics. Conclusion We introduced PersonaAgent with GraphRAG, a frame- work that integrates persona-driven prompting with graph- enhanced retrieval to provide accurate, explainable, and con- sistent personalization. By leveraging both user-specific his- tories and global community patterns, the system balances individual preferences with collective knowledge, yielding improvements in news categorization, movie tagging, and product rating. Looking forward, two promising directions emerge. First, multi-agent collaboration, where persona",
    "a corrective signal, especially when a user\u2019s preferences are strongly skewed or lack diversity across topics. Conclusion We introduced PersonaAgent with GraphRAG, a frame- work that integrates persona-driven prompting with graph- enhanced retrieval to provide accurate, explainable, and con- sistent personalization. By leveraging both user-specific his- tories and global community patterns, the system balances individual preferences with collective knowledge, yielding improvements in news categorization, movie tagging, and product rating. Looking forward, two promising directions emerge. First, multi-agent collaboration, where persona agents interact, ne- gotiate, and share knowledge, could enhance robustness and enable collective intelligence for recommendation, classifi- cation, and decision-support. Second, incorporating inverse reinforcement learning (IRL) (Beliaev and Sadigh 2024; Ke et al. 2025; Jeon et al. 2020) would allow agents to infer latent preference signals from behavior, aligning with both explicit histories and implicit reward structures. This could produce agents that better adapt to evolving goals while re- maining consistent with user values. References AI, M. 2024. LLaMA 3 8B. Anthropic. 2024. Claude 3.5 Sonnet. Inverse Reinforcement Beliaev, M.; and Sadigh, D. 2024. Learning by Estimating Expertise of Demonstrators. arXiv preprint. Extended version of AAAI publication. Zerhoudi, S.; and Granitzer, M. 2024. PersonaRAG: Enhancing Retrieval-Augmented Generation Systems with User-Centric Agents. arXiv preprint Zhang, W.; and et al. 2024. PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time. arXiv preprint Zhong, W.; Guo, L.; Gao, Q.; and et al. 2023. MemoryBank: Enhancing Large Language Models with Long-Term Mem- ory. Zou, H. P.; Huang, W.-C.; Wu, Y.; ; and et al. 2025. LLM- Based Human-Agent Collaboration and Interaction Sys- tems: A Survey. Chen, J.; and et al. 2024. From Persona to Personalization: A Survey on Role-Playing Language Agents. arXiv preprint Jeon, W.; Su, C.-Y.; Barde, P.; and et al. 2020. Regularized Inverse Reinforcement Learning. Jiang, A. Q.; and et al. 2023. Mistral 7B. Ke, J.; Wu, F.; Wang, J.; and et al. 2025. Inverse Reinforce- ment Learning with Switching Rewards and History Depen- dency. In ICLR. Submission 10850. Kenan Jiang, F. L., Li Xiong. 2024. HARBOR: Explor- ing Persona Dynamics in Multi-Agent Competition. arXiv preprint Lewis, P.; and et al. 2023. Retrieval-Augmented Genera- tion for Knowledge-Intensive NLP Tasks: A Survey. arXiv preprint Liang, S.; Zhang, Y.; and Wang, Y. 2025. C-TLSAN: Content-Enhanced Time-Aware Long-and Short-Term At- tention Network for Personalized Recommendation. arXiv preprint Lin, J.; and et al. 2023. How Can Recommender Systems Benefit from Large Language Models: A Survey. arXiv preprint Liu, J.; Shen, D.; Zhang, Y.; and et al. 2021. What Makes Good In-Context Examples for GPT-3? Mansour, S.; and et al. 2024. PAARS: Persona Aligned Agentic Retail Shoppers. arXiv preprint Ruan, J.; and et al. 2023. TPTU: Large Language Model- based AI Agents for Task Planning and Tool Usage. arXiv preprint Said, A. 2025. On explaining recommendations with Large Language Models: a review. Frontiers in Big Data, 7: 1505284. Salemi, A.; Mysore, S.; Bendersky, M.; and et al. 2023. LaMP: When Large Language Models Meet Personaliza- tion. Samuel, V.; Zou, H. P.; and et al., Y.",
    "Mansour, S.; and et al. 2024. PAARS: Persona Aligned Agentic Retail Shoppers. arXiv preprint Ruan, J.; and et al. 2023. TPTU: Large Language Model- based AI Agents for Task Planning and Tool Usage. arXiv preprint Said, A. 2025. On explaining recommendations with Large Language Models: a review. Frontiers in Big Data, 7: 1505284. Salemi, A.; Mysore, S.; Bendersky, M.; and et al. 2023. LaMP: When Large Language Models Meet Personaliza- tion. Samuel, V.; Zou, H. P.; and et al., Y. Z. 2024. PersonaGym: arXiv preprint Evaluating Persona Agents and LLMs. Touvron, H.; and et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. Wang, L.; Ma, C.; Feng, X.; and et al. 2024. A survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6). Xu, R.; and et al. 2024. Character is Destiny: Can Role- Playing Language Agents Make Persona-Driven Decisions? arXiv preprint Xu, Z.; and Zhang, Y. 2025. ing Yao, S.; Zhao, J.; Yu, D.; and et al. 2023. ReAct: Synergizing Reasoning and Acting in Language Models. Yu, P.; Xu, Z.; Wang, J.; and et al. 2025. The Application of Large Language Models in Recommendation Systems. arXiv preprint ArXiv:2501.02178v2. LLM-Enhanced Rerank- Product Recommendation. for Complementary"
  ]
}