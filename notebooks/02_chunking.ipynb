{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff6a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.chunking.chunker import clean_text, chunk_text\n",
    "\n",
    "PARSED_DIR = \"data/processed/parsed\"\n",
    "CHUNK_DIR = \"data/processed/chunks\"\n",
    "os.makedirs(CHUNK_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d017ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2511.17489.txt',\n",
       " '2511.17475.txt',\n",
       " '2511.17473.txt',\n",
       " '2511.17467.txt',\n",
       " '2302.14045.txt',\n",
       " '2312.00752.txt',\n",
       " '2402.06782.txt',\n",
       " '2511.17446.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_files = [f for f in os.listdir(PARSED_DIR) if f.endswith(\".txt\")]\n",
    "parsed_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37843878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,\n",
       " ['5 2 0 2 v o N 1 2 ] G L . s c [ 1 v 9 8 4 7 1 . 1 1 5 2 : v i X r a 1–30 Harnessing Data from Clustered LQR Systems: Personalized and Collaborative Policy Optimization Vinay Kanakeri Department of Electrical and Computer Engineering, North Carolina State University VKANAKE@NCSU.EDU Shivam Bajaj The Elmore Family School of Electrical and Computer Engineering, Purdue University BAJAJ41@PURDUE.EDU Ashwin Verma The Elmore Family School of Electrical and Computer Engineering, Purdue University VERMA240@PURDUE.EDU Vijay Gupta The Elmore Family School of Electrical and Computer Engineering, Purdue University GUPTA869@PURDUE.EDU Aritra Mitra Department of Electrical and Computer Engineering, North Carolina State University AMITRA2@NCSU.EDU Abstract It is known that reinforcement learning (RL) is data-hungry. To improve sample-efficiency of RL, it has been proposed that the learning algorithm utilize data from ‘approximately similar’ processes. However, since the process models are unknown, identifying which other processes are similar poses a challenge. In this work, we study this problem in the context of the benchmark Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting with multiple agents, each corresponding to a copy of a linear process to be controlled. The agents’ local processes can be partitioned into clusters based on similarities in dynamics and tasks. Combining ideas from sequential elimination and zeroth-order policy optimization, we propose a new algorithm that performs simultaneous clustering and learning to output a personalized policy (controller) for each cluster. Under a suitable notion of cluster separation that captures differences in closed-loop performance across systems, we prove that our approach guarantees correct clustering with high probability. Furthermore, we show that the sub-optimality gap of the policy learned for each cluster scales inversely with the size of the cluster, with no additional bias, unlike in prior works on collaborative learning-based control. Our work is the first to reveal how clustering can be used in data-driven control to learn personalized policies that enjoy statistical gains from collaboration but do not suffer sub-optimality due to inclusion of data from dissimilar processes. From a distributed implementation perspective, our method is attractive as it incurs only a mild logarithmic communication overhead. Keywords: Policy gradients for LQR; Collaborative Learning; Transfer/Multi-Task Learning. 1. Introduction The last decade or so has seen a surge of interest in model-free data-driven control (Hu et al., 2023), where control laws (policies) are learned directly from data, bypassing the need to estimate the system model as an intermediate step. Although such a framework is promising, it relies on the availability of adequate data to learn high-precision policies. Unfortunately, however, data from physical processes (such as real-world robotic environments) could be scarce and/or difficult to collect. Drawing inspiration from popular paradigms such as federated and meta-learning, some recent papers (Zhang et al., 2023; Wang et al., 2023a; Toso et al., 2024) have attempted to mitigate this challenge by exploring the idea of combining information generated by multiple environments, where each environment represents a dynamical system with an associated cost performance metric'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = parsed_files[0]\n",
    "with open(os.path.join(PARSED_DIR, sample), \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "clean = clean_text(text)\n",
    "chunks = chunk_text(clean, max_length=500, overlap=80)\n",
    "\n",
    "len(chunks), chunks[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf351fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking terminé et fichiers sauvegardés \n"
     ]
    }
   ],
   "source": [
    "def save_chunks(base_name, chunks, out_dir):\n",
    "    path = os.path.join(out_dir, base_name + \".json\")\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump({\"id\": base_name, \"chunks\": chunks}, f, indent=2)\n",
    "    return path\n",
    "\n",
    "\n",
    "for fname in parsed_files:\n",
    "    base = fname.replace(\".txt\", \"\")\n",
    "    \n",
    "    with open(os.path.join(PARSED_DIR, fname), \"r\") as f:\n",
    "        raw = f.read()\n",
    "\n",
    "    clean = clean_text(raw)\n",
    "    chunks = chunk_text(clean, max_length=500, overlap=80)\n",
    "\n",
    "    save_chunks(base, chunks, CHUNK_DIR)\n",
    "\n",
    "print(\"Chunking terminé et fichiers sauvegardés \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa9076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.processing.chunker import chunk_text\n",
    "chunks = chunk_text(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
